!!python/object:argparse.Namespace
algo: reinforce_on_policy
anneal_lr: false
batch_size: 32
buffer_batches: 1
buffer_size: 32
clip_coef: 0.2
clip_vloss: true
cuda: true
device: !!python/object/apply:torch.device
- cpu
ent_coef: 0.01
env_id: Pendulum-v1
eval_episodes: 20
eval_freq: 125000
exp_name: ppo_props_continuous
gae_lambda: 0.95
gamma: 0.99
learning_rate: 0.0001
log_stats: 1
max_grad_norm: 0.5
minibatch_size: 32
norm_adv: true
normalization_dir: null
num_envs: 1
num_minibatches: 32
num_steps: 32
policy_path: null
props: 0
props_adv: false
props_anneal_lr: 0
props_clip_coef: 0.3
props_eval: false
props_lambda: 0.3
props_learning_rate: 0.0001
props_max_grad_norm: 0.5
props_minibatch_size: 0
props_num_minibatches: 16
props_num_steps: 32
props_target_kl: 0.05
props_update_epochs: 16
reinforce: 1
results_dir: results
results_subdir: b_1/
ros: 0
run_id: 0
save_dir: results/Pendulum-v1/reinforce_on_policy/b_1
se: 0
se_epochs: 250
se_freq: null
se_lr: 0.001
se_ref: 0
seed: 0
target_kl: 0.03
torch_deterministic: true
total_timesteps: 5000000
track: false
update_epochs: 1
vf_coef: 0.5
wandb_entity: null
wandb_login_key: null
wandb_project_name: cleanRL
path: ""