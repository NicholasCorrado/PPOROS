ppo_ros_continuous.py --env-id Walker2d-v4 -s expert/b_16/no_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 0.3 --ros-lambda 0 -ros-lr 0.001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Walker2d-v4/best_model.zip --normalization-dir policies/Walker2d-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_394779/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_394779/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_394779/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_394779/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 2
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.055956751108169556]
ref [0.29353922605514526]
[0.3494959771633148]
Training time: 16 	steps per sec: 60
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.055956751108169556, -0.013432204723358154]
ref [0.29353922605514526, 0.14496442675590515]
[0.3494959771633148, 0.131532222032547]
Training time: 44 	steps per sec: 45
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939]
Training time: 85 	steps per sec: 36
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648]
Training time: 144 	steps per sec: 28
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785]
Training time: 213 	steps per sec: 23
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642]
Training time: 309 	steps per sec: 19
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035]
Training time: 421 	steps per sec: 16
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087]
Training time: 551 	steps per sec: 14
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003]
Training time: 697 	steps per sec: 13
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399]
Training time: 841 	steps per sec: 12
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659]
Training time: 949 	steps per sec: 11
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739]
Training time: 1069 	steps per sec: 11
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002]
Training time: 1203 	steps per sec: 11
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424]
Training time: 1340 	steps per sec: 10
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169]
Training time: 1477 	steps per sec: 10
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635]
Training time: 1619 	steps per sec: 10
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845]
Training time: 1759 	steps per sec: 9
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884]
Training time: 1901 	steps per sec: 9
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325]
Training time: 2044 	steps per sec: 9
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213]
Training time: 2189 	steps per sec: 9
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332]
Training time: 2334 	steps per sec: 9
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731]
Training time: 2478 	steps per sec: 9
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536]
Training time: 2620 	steps per sec: 8
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761]
Training time: 2747 	steps per sec: 8
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669]
Training time: 2876 	steps per sec: 8
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187]
Training time: 3007 	steps per sec: 8
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152]
Training time: 3148 	steps per sec: 8
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725, -0.004173435270786285]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876, 0.014700758270919323]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152, 0.010527323000133038]
Training time: 3301 	steps per sec: 8
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725, -0.004173435270786285, -0.006054190918803215]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876, 0.014700758270919323, 0.016405250877141953]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152, 0.010527323000133038, 0.010351059958338737]
Training time: 3455 	steps per sec: 8
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725, -0.004173435270786285, -0.006054190918803215, -0.006693102419376373]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876, 0.014700758270919323, 0.016405250877141953, 0.017869507893919945]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152, 0.010527323000133038, 0.010351059958338737, 0.011176405474543571]
Training time: 3605 	steps per sec: 8
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725, -0.004173435270786285, -0.006054190918803215, -0.006693102419376373, -0.007039316929876804]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876, 0.014700758270919323, 0.016405250877141953, 0.017869507893919945, 0.018071254715323448]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152, 0.010527323000133038, 0.010351059958338737, 0.011176405474543571, 0.011031937785446644]
Training time: 3765 	steps per sec: 8
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.055956751108169556, -0.013432204723358154, -0.021494343876838684, -0.03426108509302139, -0.007330812513828278, -0.0017849095165729523, -0.010086603462696075, -0.010489031672477722, -0.006413895636796951, -0.010628573596477509, -0.007282582111656666, -0.00738189835101366, -0.007822874933481216, -0.007174456492066383, -0.006045060232281685, -0.007405070587992668, -0.006702194921672344, -0.006309357471764088, -0.005228928290307522, -0.005904321558773518, -0.006192649714648724, -0.00525483675301075, -0.006700724363327026, -0.006753688678145409, -0.006900128908455372, -0.0060294922441244125, -0.005327679216861725, -0.004173435270786285, -0.006054190918803215, -0.006693102419376373, -0.007039316929876804, -0.006528324447572231]
ref [0.29353922605514526, 0.14496442675590515, 0.10239163041114807, 0.08753973990678787, 0.04981543496251106, 0.03608522191643715, 0.035618189722299576, 0.03228733316063881, 0.026185404509305954, 0.02659120038151741, 0.021787432953715324, 0.02145954966545105, 0.021053649485111237, 0.019455421715974808, 0.016767341643571854, 0.017702246084809303, 0.017159126698970795, 0.01680895686149597, 0.015650922432541847, 0.01564091071486473, 0.015297588892281055, 0.014416210353374481, 0.016082918271422386, 0.016214357689023018, 0.01747957058250904, 0.0159104373306036, 0.015437349677085876, 0.014700758270919323, 0.016405250877141953, 0.017869507893919945, 0.018071254715323448, 0.01665797084569931]
[0.3494959771633148, 0.131532222032547, 0.08089728653430939, 0.05327865481376648, 0.042484622448682785, 0.0343003123998642, 0.0255315862596035, 0.021798301488161087, 0.019771508872509003, 0.0159626267850399, 0.014504850842058659, 0.01407765131443739, 0.01323077455163002, 0.012280965223908424, 0.010722281411290169, 0.010297175496816635, 0.01045693177729845, 0.010499599389731884, 0.010421994142234325, 0.009736589156091213, 0.009104939177632332, 0.009161373600363731, 0.00938219390809536, 0.00946066901087761, 0.010579441674053669, 0.009880945086479187, 0.010109670460224152, 0.010527323000133038, 0.010351059958338737, 0.011176405474543571, 0.011031937785446644, 0.010129646398127079]
Training time: 3924 	steps per sec: 8
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Walker2d-v4/
results/Walker2d-v4/ppo_ros/
results/Walker2d-v4/ppo_ros/expert/
results/Walker2d-v4/ppo_ros/expert/b_16/
results/Walker2d-v4/ppo_ros/expert/b_16/no_lambda/
results/Walker2d-v4/ppo_ros/expert/b_16/no_lambda/run_2/
results/Walker2d-v4/ppo_ros/expert/b_16/no_lambda/run_2/evaluations.npz
results/Walker2d-v4/ppo_ros/expert/b_16/no_lambda/run_2/config.yml
results/Walker2d-v4/ppo_ros/expert/b_16/no_lambda/run_2/stats.npz
