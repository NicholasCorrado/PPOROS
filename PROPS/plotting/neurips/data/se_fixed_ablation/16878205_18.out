ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_1435722/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_1435722/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_1435722/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_1435722/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 3
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.5807764530181885]
ref [2.6117782592773438]
[3.1925547122955322]
Training time: 14 	steps per sec: 70
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.5807764530181885, -0.07806408405303955]
ref [2.6117782592773438, 0.8741307258605957]
[3.1925547122955322, 0.7960666418075562]
Training time: 33 	steps per sec: 61
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275]
Training time: 66 	steps per sec: 46
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723]
Training time: 107 	steps per sec: 38
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282]
Training time: 157 	steps per sec: 32
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197]
Training time: 213 	steps per sec: 28
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906]
Training time: 276 	steps per sec: 25
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109]
Training time: 345 	steps per sec: 23
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624]
Training time: 427 	steps per sec: 21
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675]
Training time: 516 	steps per sec: 19
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707]
Training time: 606 	steps per sec: 18
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882]
Training time: 703 	steps per sec: 17
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746]
Training time: 804 	steps per sec: 16
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265]
Training time: 919 	steps per sec: 15
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342]
Training time: 1041 	steps per sec: 14
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664]
Training time: 1164 	steps per sec: 14
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897]
Training time: 1285 	steps per sec: 13
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686]
Training time: 1410 	steps per sec: 13
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116]
Training time: 1536 	steps per sec: 12
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075]
Training time: 1659 	steps per sec: 12
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014]
Training time: 1781 	steps per sec: 12
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131]
Training time: 1906 	steps per sec: 11
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663]
Training time: 2027 	steps per sec: 11
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155]
Training time: 2149 	steps per sec: 11
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784]
Training time: 2266 	steps per sec: 11
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737]
Training time: 2390 	steps per sec: 11
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396]
Training time: 2562 	steps per sec: 10
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185, -0.005177393555641174]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615, 0.04385685920715332]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396, 0.038679465651512146]
Training time: 2708 	steps per sec: 10
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185, -0.005177393555641174, -0.008893165737390518]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615, 0.04385685920715332, 0.04807320609688759]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396, 0.038679465651512146, 0.03918004035949707]
Training time: 2835 	steps per sec: 10
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185, -0.005177393555641174, -0.008893165737390518, -0.0019209235906600952]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615, 0.04385685920715332, 0.04807320609688759, 0.04191627353429794]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396, 0.038679465651512146, 0.03918004035949707, 0.03999534994363785]
Training time: 2954 	steps per sec: 10
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185, -0.005177393555641174, -0.008893165737390518, -0.0019209235906600952, -0.0031517483294010162]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615, 0.04385685920715332, 0.04807320609688759, 0.04191627353429794, 0.043253012001514435]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396, 0.038679465651512146, 0.03918004035949707, 0.03999534994363785, 0.04010126367211342]
Training time: 3084 	steps per sec: 10
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.5807764530181885, -0.07806408405303955, -0.03742226958274841, 0.038033872842788696, 0.009548783302307129, -0.0073277950286865234, -0.017694681882858276, 0.0028919875621795654, -0.01636774092912674, -0.004641100764274597, -0.012276560068130493, -0.01503535732626915, -0.00599350780248642, -0.009727049618959427, -0.006514575332403183, -0.011073432862758636, -0.006028454750776291, -0.008829060941934586, -0.004661548882722855, -0.006844524294137955, -0.004063572734594345, -0.0038619451224803925, -0.005393370985984802, -0.00968068465590477, -0.0055046118795871735, -0.005993317812681198, -0.0057072266936302185, -0.005177393555641174, -0.008893165737390518, -0.0019209235906600952, -0.0031517483294010162, -0.002869732677936554]
ref [2.6117782592773438, 0.8741307258605957, 0.42887184023857117, 0.24059763550758362, 0.18602094054222107, 0.1519576460123062, 0.12552282214164734, 0.08743643760681152, 0.09207507967948914, 0.07265569269657135, 0.06995025277137756, 0.06588848680257797, 0.05214853584766388, 0.052637793123722076, 0.045577991753816605, 0.0476536825299263, 0.043697867542505264, 0.046549372375011444, 0.04258420318365097, 0.045381806790828705, 0.04274287447333336, 0.043268829584121704, 0.04429231956601143, 0.04727386683225632, 0.04254956170916557, 0.043305736035108566, 0.044642094522714615, 0.04385685920715332, 0.04807320609688759, 0.04191627353429794, 0.043253012001514435, 0.04381515830755234]
[3.1925547122955322, 0.7960666418075562, 0.39144957065582275, 0.2786315083503723, 0.1955697238445282, 0.1446298509836197, 0.10782814025878906, 0.09032842516899109, 0.0757073387503624, 0.06801459193229675, 0.05767369270324707, 0.05085312947630882, 0.04615502804517746, 0.04291074350476265, 0.03906341642141342, 0.036580249667167664, 0.03766941279172897, 0.03772031143307686, 0.037922654300928116, 0.03853728249669075, 0.038679301738739014, 0.03940688446164131, 0.03889894858002663, 0.03759318217635155, 0.0370449498295784, 0.03731241822242737, 0.038934867829084396, 0.038679465651512146, 0.03918004035949707, 0.03999534994363785, 0.04010126367211342, 0.040945425629615784]
Training time: 3215 	steps per sec: 10
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_3/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_3/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_3/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_3/config.yml
