ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_3167085/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_3167085/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_3167085/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_3167085/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 4
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.13344788551330566]
ref [3.369347333908081]
[3.2358994483947754]
Training time: 13 	steps per sec: 75
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.13344788551330566, 0.01752030849456787]
ref [3.369347333908081, 0.65169358253479]
[3.2358994483947754, 0.6692138910293579]
Training time: 34 	steps per sec: 59
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578]
Training time: 65 	steps per sec: 47
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545]
Training time: 122 	steps per sec: 33
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768]
Training time: 198 	steps per sec: 25
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712]
Training time: 285 	steps per sec: 21
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317]
Training time: 376 	steps per sec: 19
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915]
Training time: 470 	steps per sec: 17
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974]
Training time: 582 	steps per sec: 15
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472]
Training time: 740 	steps per sec: 13
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184]
Training time: 889 	steps per sec: 12
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505]
Training time: 1036 	steps per sec: 11
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485]
Training time: 1178 	steps per sec: 11
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718]
Training time: 1347 	steps per sec: 10
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436]
Training time: 1539 	steps per sec: 9
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474]
Training time: 1740 	steps per sec: 9
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446]
Training time: 1940 	steps per sec: 8
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096]
Training time: 2127 	steps per sec: 8
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756]
Training time: 2324 	steps per sec: 8
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807]
Training time: 2517 	steps per sec: 8
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426]
Training time: 2718 	steps per sec: 7
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442]
Training time: 2905 	steps per sec: 7
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692]
Training time: 3107 	steps per sec: 7
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796]
Training time: 3315 	steps per sec: 7
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764]
Training time: 3527 	steps per sec: 7
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054]
Training time: 3742 	steps per sec: 7
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148]
Training time: 3945 	steps per sec: 7
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316, -0.003412976861000061]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795, 0.042784590274095535]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148, 0.039371613413095474]
Training time: 4142 	steps per sec: 6
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316, -0.003412976861000061, -0.005292542278766632]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795, 0.042784590274095535, 0.04537689685821533]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148, 0.039371613413095474, 0.0400843545794487]
Training time: 4334 	steps per sec: 6
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316, -0.003412976861000061, -0.005292542278766632, -0.004130542278289795]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795, 0.042784590274095535, 0.04537689685821533, 0.045443058013916016]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148, 0.039371613413095474, 0.0400843545794487, 0.04131251573562622]
Training time: 4524 	steps per sec: 6
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316, -0.003412976861000061, -0.005292542278766632, -0.004130542278289795, -0.0020787715911865234]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795, 0.042784590274095535, 0.04537689685821533, 0.045443058013916016, 0.04268019273877144]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148, 0.039371613413095474, 0.0400843545794487, 0.04131251573562622, 0.040601421147584915]
Training time: 4719 	steps per sec: 6
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.13344788551330566, 0.01752030849456787, -0.023089706897735596, -0.009776324033737183, -0.014838457107543945, -0.035239532589912415, -0.015477627515792847, -0.01572927087545395, -0.0221271812915802, -0.012565910816192627, -0.010974224656820297, -0.012984942644834518, -0.013388402760028839, -0.010776985436677933, -0.009955253452062607, -0.00935531035065651, -0.0048879459500312805, -0.008248131722211838, -0.00790075957775116, -0.0039066895842552185, -0.003445621579885483, -0.0019530132412910461, -0.00526084378361702, -0.006378848105669022, -0.007337961345911026, -0.008976675570011139, -0.004750773310661316, -0.003412976861000061, -0.005292542278766632, -0.004130542278289795, -0.0020787715911865234, -0.006725568324327469]
ref [3.369347333908081, 0.65169358253479, 0.4077676832675934, 0.27280721068382263, 0.20322374999523163, 0.1767558604478836, 0.11999119818210602, 0.0969996303319931, 0.09354717284440994, 0.07852940261363983, 0.07078702002763748, 0.06508631259202957, 0.05967158451676369, 0.053487829864025116, 0.049869928508996964, 0.046590693295001984, 0.04199987277388573, 0.045790333300828934, 0.04607640951871872, 0.04389617592096329, 0.04389660805463791, 0.042851366102695465, 0.04611317068338394, 0.04695343226194382, 0.04558844119310379, 0.04551892355084419, 0.043350473046302795, 0.042784590274095535, 0.04537689685821533, 0.045443058013916016, 0.04268019273877144, 0.047012098133563995]
[3.2358994483947754, 0.6692138910293579, 0.3846779763698578, 0.26303088665008545, 0.18838529288768768, 0.1415163278579712, 0.10451357066631317, 0.08127035945653915, 0.07141999155282974, 0.0659634917974472, 0.059812795370817184, 0.05210136994719505, 0.04628318175673485, 0.04271084442734718, 0.03991467505693436, 0.037235382944345474, 0.037111926823854446, 0.037542201578617096, 0.03817564994096756, 0.03998948633670807, 0.040450986474752426, 0.04089835286140442, 0.04085232689976692, 0.040574584156274796, 0.038250479847192764, 0.036542247980833054, 0.03859969973564148, 0.039371613413095474, 0.0400843545794487, 0.04131251573562622, 0.040601421147584915, 0.040286529809236526]
Training time: 4927 	steps per sec: 6
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_4/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_4/config.yml
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_4/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_4/stats.npz
