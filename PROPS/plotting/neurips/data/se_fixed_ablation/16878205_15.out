ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_782093/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_782093/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_782093/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_782093/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 0
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.8605575561523438]
ref [2.1767613887786865]
[3.0373189449310303]
Training time: 17 	steps per sec: 57
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.8605575561523438, -0.04143881797790527]
ref [2.1767613887786865, 0.7513235807418823]
[3.0373189449310303, 0.709884762763977]
Training time: 44 	steps per sec: 45
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549]
Training time: 88 	steps per sec: 34
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496]
Training time: 150 	steps per sec: 27
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878]
Training time: 257 	steps per sec: 19
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234]
Training time: 445 	steps per sec: 13
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657]
Training time: 560 	steps per sec: 12
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121]
Training time: 699 	steps per sec: 11
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819]
Training time: 877 	steps per sec: 10
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896]
Training time: 1080 	steps per sec: 9
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126]
Training time: 1254 	steps per sec: 8
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194]
Training time: 1439 	steps per sec: 8
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963]
Training time: 1601 	steps per sec: 8
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074]
Training time: 1770 	steps per sec: 8
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894]
Training time: 1945 	steps per sec: 7
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784]
Training time: 2161 	steps per sec: 7
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012]
Training time: 2399 	steps per sec: 7
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426]
Training time: 2645 	steps per sec: 6
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638]
Training time: 2848 	steps per sec: 6
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717]
Training time: 3094 	steps per sec: 6
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446]
Training time: 3335 	steps per sec: 6
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664]
Training time: 3572 	steps per sec: 6
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835]
Training time: 3795 	steps per sec: 6
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642]
Training time: 4051 	steps per sec: 6
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214]
Training time: 4294 	steps per sec: 5
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784]
Training time: 4539 	steps per sec: 5
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544]
Training time: 4778 	steps per sec: 5
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923, -0.007802020758390427]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336, 0.04492183029651642]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544, 0.03711980953812599]
Training time: 5054 	steps per sec: 5
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923, -0.007802020758390427, -0.004094570875167847]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336, 0.04492183029651642, 0.04283621534705162]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544, 0.03711980953812599, 0.038741644471883774]
Training time: 5296 	steps per sec: 5
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923, -0.007802020758390427, -0.004094570875167847, -0.007869135588407516]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336, 0.04492183029651642, 0.04283621534705162, 0.04672582820057869]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544, 0.03711980953812599, 0.038741644471883774, 0.03885669261217117]
Training time: 5490 	steps per sec: 5
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923, -0.007802020758390427, -0.004094570875167847, -0.007869135588407516, -0.005166307091712952]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336, 0.04492183029651642, 0.04283621534705162, 0.04672582820057869, 0.04418087378144264]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544, 0.03711980953812599, 0.038741644471883774, 0.03885669261217117, 0.03901456668972969]
Training time: 5690 	steps per sec: 5
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.8605575561523438, -0.04143881797790527, -0.09502315521240234, -0.04680630564689636, -0.026172101497650146, -0.006917506456375122, -0.011235512793064117, -0.008349157869815826, 0.0017754137516021729, -0.005654938519001007, -0.0031644217669963837, -0.009392254054546356, -0.011974301189184189, -0.007553648203611374, -0.007029198110103607, -0.008089985698461533, -0.007137913256883621, -0.0047090426087379456, -0.0034637711942195892, -0.0031003616750240326, -0.0066257864236831665, -0.004835978150367737, -0.008511707186698914, -0.007189713418483734, -0.008299659937620163, -0.008364949375391006, -0.008116651326417923, -0.007802020758390427, -0.004094570875167847, -0.007869135588407516, -0.005166307091712952, -0.004661519080400467]
ref [2.1767613887786865, 0.7513235807418823, 0.4875071048736572, 0.2882706820964813, 0.20277300477027893, 0.14458002150058746, 0.12429691851139069, 0.10428283363580704, 0.08039365708827972, 0.07506413012742996, 0.06337747722864151, 0.0635916218161583, 0.06038091704249382, 0.05106024071574211, 0.0467461459338665, 0.044246573001146317, 0.04495786875486374, 0.04422867298126221, 0.04344474896788597, 0.0435417965054512, 0.04577391594648361, 0.042842864990234375, 0.046604178845882416, 0.045604996383190155, 0.04725676774978638, 0.04637947678565979, 0.04647787660360336, 0.04492183029651642, 0.04283621534705162, 0.04672582820057869, 0.04418087378144264, 0.042587365955114365]
[3.0373189449310303, 0.709884762763977, 0.3924839496612549, 0.24146437644958496, 0.17660090327262878, 0.13766251504421234, 0.11306140571832657, 0.09593367576599121, 0.0821690708398819, 0.06940919160842896, 0.060213055461645126, 0.05419936776161194, 0.04840661585330963, 0.04350659251213074, 0.039716947823762894, 0.036156587302684784, 0.03781995549798012, 0.03951963037252426, 0.03998097777366638, 0.04044143483042717, 0.039148129522800446, 0.03800688683986664, 0.0380924716591835, 0.03841528296470642, 0.038957107812166214, 0.038014527410268784, 0.03836122527718544, 0.03711980953812599, 0.038741644471883774, 0.03885669261217117, 0.03901456668972969, 0.0379258468747139]
Training time: 5879 	steps per sec: 5
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_0/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_0/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_0/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_0/config.yml
