ppo_ros_continuous.py --env-id Ant-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Ant-v4/best_model.zip --normalization-dir policies/Ant-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_17782/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_17782/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_17782/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_17782/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 0
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.17507755756378174]
ref [0.7589143514633179]
[0.5838367938995361]
Training time: 34 	steps per sec: 29
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.17507755756378174, -0.074154794216156]
ref [0.7589143514633179, 0.26676249504089355]
[0.5838367938995361, 0.19260770082473755]
Training time: 79 	steps per sec: 25
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072]
Training time: 138 	steps per sec: 22
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662]
Training time: 207 	steps per sec: 19
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445]
Training time: 285 	steps per sec: 17
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618]
Training time: 380 	steps per sec: 16
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085]
Training time: 483 	steps per sec: 14
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264]
Training time: 604 	steps per sec: 13
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082]
Training time: 735 	steps per sec: 12
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345]
Training time: 876 	steps per sec: 11
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792]
Training time: 1027 	steps per sec: 10
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372]
Training time: 1195 	steps per sec: 10
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224]
Training time: 1382 	steps per sec: 9
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414]
Training time: 1590 	steps per sec: 9
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476]
Training time: 1809 	steps per sec: 8
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866]
Training time: 2041 	steps per sec: 8
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048]
Training time: 2280 	steps per sec: 7
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207]
Training time: 2514 	steps per sec: 7
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354]
Training time: 2746 	steps per sec: 7
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893]
Training time: 2984 	steps per sec: 6
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913]
Training time: 3216 	steps per sec: 6
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308]
Training time: 3442 	steps per sec: 6
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418]
Training time: 3673 	steps per sec: 6
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538]
Training time: 3909 	steps per sec: 6
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672]
Training time: 4145 	steps per sec: 6
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247]
Training time: 4381 	steps per sec: 6
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974]
Training time: 4620 	steps per sec: 5
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435, 0.0014482084661722183]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798, 0.023000072687864304]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522]
Training time: 4858 	steps per sec: 5
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435, 0.0014482084661722183, 0.002621527761220932]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798, 0.023000072687864304, 0.02276698499917984]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772]
Training time: 5093 	steps per sec: 5
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435, 0.0014482084661722183, 0.002621527761220932, 0.003668205812573433]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798, 0.023000072687864304, 0.02276698499917984, 0.02072075381875038]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814]
Training time: 5330 	steps per sec: 5
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435, 0.0014482084661722183, 0.002621527761220932, 0.003668205812573433, -0.0017570685595273972]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798, 0.023000072687864304, 0.02276698499917984, 0.02072075381875038, 0.022918732836842537]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814, 0.02116166427731514]
Training time: 5565 	steps per sec: 5
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.17507755756378174, -0.074154794216156, -0.05073346197605133, -0.02897978574037552, -0.012805365025997162, -0.008920252323150635, -0.017917778342962265, -0.012693960219621658, -0.01467505656182766, -0.006400996819138527, -0.007061300799250603, -0.005060037598013878, -0.0061463359743356705, 0.010550567880272865, 0.007264267653226852, 0.007219115272164345, 0.008177096024155617, 0.0070241596549749374, 0.010758284479379654, 0.009278630837798119, 0.009132614359259605, 0.00860518217086792, 0.008207269012928009, 0.0066474322229623795, 0.010791635140776634, 0.0019208751618862152, 0.0024765413254499435, 0.0014482084661722183, 0.002621527761220932, 0.003668205812573433, -0.0017570685595273972, 0.0006444081664085388]
ref [0.7589143514633179, 0.26676249504089355, 0.16355277597904205, 0.10965174436569214, 0.07053481787443161, 0.05669388175010681, 0.05714242532849312, 0.04424098879098892, 0.04129856452345848, 0.03605416417121887, 0.03326289355754852, 0.02887483686208725, 0.027227869257330894, 0.02519928850233555, 0.023790575563907623, 0.02215219847857952, 0.02243543043732643, 0.024172507226467133, 0.0197901651263237, 0.021263547241687775, 0.021422594785690308, 0.02144131436944008, 0.02137403003871441, 0.02318038046360016, 0.020049113780260086, 0.023235909640789032, 0.022623945027589798, 0.023000072687864304, 0.02276698499917984, 0.02072075381875038, 0.022918732836842537, 0.020733237266540527]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814, 0.02116166427731514, 0.021377645432949066]
Training time: 5796 	steps per sec: 5
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Ant-v4/
results/Ant-v4/ppo_ros/
results/Ant-v4/ppo_ros/expert/
results/Ant-v4/ppo_ros/expert/b_16/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/evaluations.npz
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/stats.npz
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/config.yml
