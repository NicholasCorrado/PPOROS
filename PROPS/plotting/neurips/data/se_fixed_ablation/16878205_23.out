ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 0.3 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_3235783/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_3235783/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_3235783/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_3235783/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 3
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.2543461322784424]
ref [3.3403751850128174]
[3.086029052734375]
Training time: 16 	steps per sec: 63
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.2543461322784424, -0.0060266852378845215]
ref [3.3403751850128174, 0.8361576199531555]
[3.086029052734375, 0.830130934715271]
Training time: 40 	steps per sec: 50
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336]
[3.086029052734375, 0.830130934715271, 0.42124417424201965]
Training time: 73 	steps per sec: 41
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574]
Training time: 115 	steps per sec: 35
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847]
Training time: 162 	steps per sec: 31
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096]
Training time: 225 	steps per sec: 27
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276]
Training time: 303 	steps per sec: 23
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452]
Training time: 389 	steps per sec: 21
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603]
Training time: 485 	steps per sec: 18
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057]
Training time: 586 	steps per sec: 17
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996]
Training time: 695 	steps per sec: 16
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269]
Training time: 811 	steps per sec: 15
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274]
Training time: 937 	steps per sec: 14
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381]
Training time: 1074 	steps per sec: 13
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294]
Training time: 1227 	steps per sec: 12
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355]
Training time: 1383 	steps per sec: 11
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519]
Training time: 1539 	steps per sec: 11
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197]
Training time: 1692 	steps per sec: 10
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707]
Training time: 1846 	steps per sec: 10
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638]
Training time: 2012 	steps per sec: 10
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852]
Training time: 2164 	steps per sec: 9
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392]
Training time: 2314 	steps per sec: 9
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447]
Training time: 2460 	steps per sec: 9
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519]
Training time: 2612 	steps per sec: 9
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602]
Training time: 2769 	steps per sec: 9
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322]
Training time: 2938 	steps per sec: 9
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425]
Training time: 3095 	steps per sec: 8
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755, -0.00445064902305603]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178, 0.045961108058691025]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425, 0.041510459035634995]
Training time: 3230 	steps per sec: 8
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755, -0.00445064902305603, -0.006432373076677322]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178, 0.045961108058691025, 0.046545401215553284]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425, 0.041510459035634995, 0.04011302813887596]
Training time: 3370 	steps per sec: 8
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755, -0.00445064902305603, -0.006432373076677322, -0.004069823771715164]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178, 0.045961108058691025, 0.046545401215553284, 0.04313667118549347]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425, 0.041510459035634995, 0.04011302813887596, 0.039066847413778305]
Training time: 3526 	steps per sec: 8
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755, -0.00445064902305603, -0.006432373076677322, -0.004069823771715164, -0.002038385719060898]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178, 0.045961108058691025, 0.046545401215553284, 0.04313667118549347, 0.04148077592253685]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425, 0.041510459035634995, 0.04011302813887596, 0.039066847413778305, 0.03944239020347595]
Training time: 3685 	steps per sec: 8
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.2543461322784424, -0.0060266852378845215, 0.028855353593826294, 0.026751458644866943, -0.0001595020294189453, 0.014083579182624817, 0.004195265471935272, -0.009865745902061462, 0.006307341158390045, -0.008487291634082794, -0.0011344552040100098, 0.0009728968143463135, -0.00530584529042244, -0.009730171412229538, -0.005556557327508926, -0.008369222283363342, -0.00516480952501297, -0.004727330058813095, -0.007961183786392212, -0.0040852464735507965, -0.004177812486886978, -0.007271952927112579, -0.009061682969331741, -0.005376942455768585, -0.002767164260149002, -0.002947937697172165, -0.0022900886833667755, -0.00445064902305603, -0.006432373076677322, -0.004069823771715164, -0.002038385719060898, -0.004616111516952515]
ref [3.3403751850128174, 0.8361576199531555, 0.39238882064819336, 0.2462652325630188, 0.19642707705497742, 0.1340564787387848, 0.11501229554414749, 0.10533314943313599, 0.07872649282217026, 0.08034028112888336, 0.06600621342658997, 0.055985044687986374, 0.057047341018915176, 0.056061893701553345, 0.04643946886062622, 0.0447305403649807, 0.04202037304639816, 0.042530208826065063, 0.04673869162797928, 0.04291866347193718, 0.0440206453204155, 0.0474056750535965, 0.04775852710008621, 0.04528476297855377, 0.04237506166100502, 0.04211307689547539, 0.04229838401079178, 0.045961108058691025, 0.046545401215553284, 0.04313667118549347, 0.04148077592253685, 0.042552925646305084]
[3.086029052734375, 0.830130934715271, 0.42124417424201965, 0.27301669120788574, 0.19626757502555847, 0.1481400579214096, 0.11920756101608276, 0.09546740353107452, 0.0850338339805603, 0.07185298949480057, 0.06487175822257996, 0.05695794150233269, 0.05174149572849274, 0.04633172228932381, 0.040882911533117294, 0.036361318081617355, 0.03685556352138519, 0.03780287876725197, 0.03877750784158707, 0.03883341699838638, 0.03984283283352852, 0.04013372212648392, 0.03869684413075447, 0.03990782052278519, 0.03960789740085602, 0.03916513919830322, 0.040008295327425, 0.041510459035634995, 0.04011302813887596, 0.039066847413778305, 0.03944239020347595, 0.03793681412935257]
Training time: 3843 	steps per sec: 8
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_3/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_3/config.yml
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_3/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_3/stats.npz
