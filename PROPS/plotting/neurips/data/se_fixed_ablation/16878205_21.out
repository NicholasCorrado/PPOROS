ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 0.3 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_1862902/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_1862902/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_1862902/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_1862902/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 1
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.038654327392578125]
ref [2.2302515506744385]
[2.1915972232818604]
Training time: 16 	steps per sec: 63
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.038654327392578125, -0.021163880825042725]
ref [2.2302515506744385, 0.7783985733985901]
[2.1915972232818604, 0.7572346925735474]
Training time: 41 	steps per sec: 49
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404]
Training time: 69 	steps per sec: 44
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413]
Training time: 109 	steps per sec: 37
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946]
Training time: 158 	steps per sec: 32
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948]
Training time: 218 	steps per sec: 28
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866]
Training time: 281 	steps per sec: 25
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447]
Training time: 358 	steps per sec: 22
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485]
Training time: 440 	steps per sec: 20
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428]
Training time: 529 	steps per sec: 19
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981]
Training time: 627 	steps per sec: 17
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935]
Training time: 738 	steps per sec: 16
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294]
Training time: 855 	steps per sec: 15
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494]
Training time: 985 	steps per sec: 14
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315]
Training time: 1121 	steps per sec: 13
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792]
Training time: 1263 	steps per sec: 12
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741]
Training time: 1411 	steps per sec: 12
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195]
Training time: 1540 	steps per sec: 11
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296]
Training time: 1687 	steps per sec: 11
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253]
Training time: 1817 	steps per sec: 11
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204]
Training time: 1954 	steps per sec: 11
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086]
Training time: 2086 	steps per sec: 10
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391]
Training time: 2235 	steps per sec: 10
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487]
Training time: 2380 	steps per sec: 10
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054]
Training time: 2519 	steps per sec: 10
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997]
Training time: 2655 	steps per sec: 10
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659]
Training time: 2798 	steps per sec: 9
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854, -0.000650264322757721]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776, 0.04229522496461868]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659, 0.04164496064186096]
Training time: 2940 	steps per sec: 9
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854, -0.000650264322757721, -0.006189130246639252]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776, 0.04229522496461868, 0.04709188640117645]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659, 0.04164496064186096, 0.0409027561545372]
Training time: 3074 	steps per sec: 9
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854, -0.000650264322757721, -0.006189130246639252, -0.0032970234751701355]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776, 0.04229522496461868, 0.04709188640117645, 0.04482119157910347]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659, 0.04164496064186096, 0.0409027561545372, 0.041524168103933334]
Training time: 3200 	steps per sec: 9
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854, -0.000650264322757721, -0.006189130246639252, -0.0032970234751701355, -0.001771293580532074]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776, 0.04229522496461868, 0.04709188640117645, 0.04482119157910347, 0.04219173640012741]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659, 0.04164496064186096, 0.0409027561545372, 0.041524168103933334, 0.04042044281959534]
Training time: 3342 	steps per sec: 9
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.038654327392578125, -0.021163880825042725, 0.11789259314537048, 0.039236366748809814, 0.028258442878723145, -0.01917862892150879, -0.001803576946258545, -0.007159896194934845, -0.006602637469768524, -0.01541251689195633, -0.010900039225816727, -0.009441167116165161, -0.014976948499679565, -0.011045891791582108, -0.009324286133050919, -0.0088646300137043, -0.00760495662689209, -0.012163881212472916, -0.010455764830112457, -0.008162766695022583, -0.006639685481786728, -0.010033737868070602, -0.00943305715918541, -0.005072537809610367, -0.007063079625368118, -0.008981402963399887, -0.0014728717505931854, -0.000650264322757721, -0.006189130246639252, -0.0032970234751701355, -0.001771293580532074, -0.004463165998458862]
ref [2.2302515506744385, 0.7783985733985901, 0.34903788566589355, 0.2530771493911743, 0.1892663538455963, 0.16824419796466827, 0.11379034072160721, 0.10340053588151932, 0.08505109697580338, 0.08100476861000061, 0.06999779492616653, 0.05933558940887451, 0.06003471463918686, 0.05138881877064705, 0.04678618162870407, 0.04331214725971222, 0.0417889803647995, 0.04815986007452011, 0.04665228724479675, 0.04477240890264511, 0.04420454055070877, 0.04497542977333069, 0.04572231322526932, 0.041902411729097366, 0.04449423775076866, 0.04704512283205986, 0.042364511638879776, 0.04229522496461868, 0.04709188640117645, 0.04482119157910347, 0.04219173640012741, 0.04435594379901886]
[2.1915972232818604, 0.7572346925735474, 0.46693047881126404, 0.29231351613998413, 0.21752479672431946, 0.14906556904315948, 0.11198676377534866, 0.09624063968658447, 0.07844845950603485, 0.06559225171804428, 0.05909775570034981, 0.04989442229270935, 0.045057766139507294, 0.04034292697906494, 0.03746189549565315, 0.03444751724600792, 0.03418402373790741, 0.035995978862047195, 0.036196522414684296, 0.03660964220762253, 0.03756485506892204, 0.034941691905260086, 0.03628925606608391, 0.036829873919487, 0.03743115812540054, 0.03806371986865997, 0.04089163988828659, 0.04164496064186096, 0.0409027561545372, 0.041524168103933334, 0.04042044281959534, 0.03989277780056]
Training time: 3482 	steps per sec: 9
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_1/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_1/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_1/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_1/config.yml
