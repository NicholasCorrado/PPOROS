ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_3854603/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_3854603/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_3854603/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_3854603/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 2
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.08085513114929199]
ref [3.0089898109436035]
[2.9281346797943115]
Training time: 18 	steps per sec: 54
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.08085513114929199, 0.18043816089630127]
ref [3.0089898109436035, 0.6673528552055359]
[2.9281346797943115, 0.8477910161018372]
Training time: 46 	steps per sec: 43
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082]
Training time: 84 	steps per sec: 36
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255]
Training time: 144 	steps per sec: 28
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537]
Training time: 217 	steps per sec: 23
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113]
Training time: 305 	steps per sec: 20
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613]
Training time: 398 	steps per sec: 17
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355]
Training time: 501 	steps per sec: 16
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422]
Training time: 612 	steps per sec: 15
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175]
Training time: 734 	steps per sec: 13
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568]
Training time: 872 	steps per sec: 12
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624]
Training time: 1026 	steps per sec: 11
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891]
Training time: 1198 	steps per sec: 11
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865]
Training time: 1386 	steps per sec: 10
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953]
Training time: 1579 	steps per sec: 9
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824]
Training time: 1776 	steps per sec: 9
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937]
Training time: 1978 	steps per sec: 8
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666]
Training time: 2198 	steps per sec: 8
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028]
Training time: 2412 	steps per sec: 8
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496]
Training time: 2629 	steps per sec: 7
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435]
Training time: 2853 	steps per sec: 7
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136]
Training time: 3091 	steps per sec: 7
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285]
Training time: 3320 	steps per sec: 7
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034]
Training time: 3514 	steps per sec: 6
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131]
Training time: 3744 	steps per sec: 6
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943]
Training time: 4022 	steps per sec: 6
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644]
Training time: 4296 	steps per sec: 6
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622, -0.0044501423835754395]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606, 0.04496833682060242]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644, 0.04051819443702698]
Training time: 4546 	steps per sec: 6
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622, -0.0044501423835754395, -0.008071180433034897]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606, 0.04496833682060242, 0.04727790877223015]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644, 0.04051819443702698, 0.03920672833919525]
Training time: 4801 	steps per sec: 6
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622, -0.0044501423835754395, -0.008071180433034897, -0.0031464993953704834]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606, 0.04496833682060242, 0.04727790877223015, 0.043205030262470245]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644, 0.04051819443702698, 0.03920672833919525, 0.04005853086709976]
Training time: 5133 	steps per sec: 5
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622, -0.0044501423835754395, -0.008071180433034897, -0.0031464993953704834, -0.001573074609041214]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606, 0.04496833682060242, 0.04727790877223015, 0.043205030262470245, 0.042324066162109375]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644, 0.04051819443702698, 0.03920672833919525, 0.04005853086709976, 0.04075099155306816]
Training time: 5378 	steps per sec: 5
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.08085513114929199, 0.18043816089630127, -0.0386662483215332, 0.003494560718536377, -0.017333105206489563, -0.018146783113479614, -0.02175690233707428, -0.01651930809020996, -0.014007411897182465, -0.013998270034790039, -0.017557665705680847, -0.010073773562908173, -0.005025245249271393, -0.004329953342676163, -0.01024528220295906, -0.004482705146074295, -0.01022874191403389, -0.009661782532930374, -0.004681423306465149, -0.010324425995349884, -0.008897040039300919, -0.006032630801200867, -0.009358089417219162, -0.006062690168619156, -0.0030707716941833496, -0.004465147852897644, -0.006012395024299622, -0.0044501423835754395, -0.008071180433034897, -0.0031464993953704834, -0.001573074609041214, -0.002516854554414749]
ref [3.0089898109436035, 0.6673528552055359, 0.40969744324684143, 0.25445127487182617, 0.18907399475574493, 0.14794935286045074, 0.1292637288570404, 0.10305759310722351, 0.08778336644172668, 0.08238537609577179, 0.07700522989034653, 0.06265158206224442, 0.0530514121055603, 0.048019375652074814, 0.05089631304144859, 0.04085209220647812, 0.04696228727698326, 0.04656803980469704, 0.04065709561109543, 0.04661685973405838, 0.046815529465675354, 0.04454445838928223, 0.04852921515703201, 0.04559812322258949, 0.04184284061193466, 0.04314707592129707, 0.04597627371549606, 0.04496833682060242, 0.04727790877223015, 0.043205030262470245, 0.042324066162109375, 0.04378356784582138]
[2.9281346797943115, 0.8477910161018372, 0.3710311949253082, 0.25794583559036255, 0.17174088954925537, 0.12980256974697113, 0.10750682651996613, 0.08653828501701355, 0.07377595454454422, 0.06838710606098175, 0.05944756418466568, 0.05257780849933624, 0.04802616685628891, 0.04368942230939865, 0.04065103083848953, 0.036369387060403824, 0.03673354536294937, 0.03690625727176666, 0.03597567230463028, 0.036292433738708496, 0.037918489426374435, 0.03851182758808136, 0.03917112573981285, 0.03953543305397034, 0.03877206891775131, 0.03868192806839943, 0.03996387869119644, 0.04051819443702698, 0.03920672833919525, 0.04005853086709976, 0.04075099155306816, 0.04126671329140663]
Training time: 5579 	steps per sec: 5
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_2/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_2/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_2/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_2/config.yml
