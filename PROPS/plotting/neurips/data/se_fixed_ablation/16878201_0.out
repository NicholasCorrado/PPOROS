ppo_ros_continuous.py --env-id Ant-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Ant-v4/best_model.zip --normalization-dir policies/Ant-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_4857/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_4857/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_4857/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_4857/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 0
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-0.19644564390182495]
ref [0.7802824378013611]
[0.5838367938995361]
Training time: 37 	steps per sec: 26
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-0.19644564390182495, -0.02782924473285675]
ref [0.7802824378013611, 0.2204369455575943]
[0.5838367938995361, 0.19260770082473755]
Training time: 91 	steps per sec: 22
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072]
Training time: 160 	steps per sec: 19
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662]
Training time: 236 	steps per sec: 17
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445]
Training time: 321 	steps per sec: 15
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618]
Training time: 431 	steps per sec: 14
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085]
Training time: 549 	steps per sec: 13
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264]
Training time: 696 	steps per sec: 11
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082]
Training time: 842 	steps per sec: 10
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345]
Training time: 1005 	steps per sec: 10
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792]
Training time: 1171 	steps per sec: 9
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372]
Training time: 1354 	steps per sec: 9
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224]
Training time: 1552 	steps per sec: 8
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414]
Training time: 1768 	steps per sec: 8
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476]
Training time: 1978 	steps per sec: 7
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866]
Training time: 2213 	steps per sec: 7
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048]
Training time: 2453 	steps per sec: 7
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207]
Training time: 2690 	steps per sec: 6
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354]
Training time: 2924 	steps per sec: 6
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893]
Training time: 3165 	steps per sec: 6
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913]
Training time: 3401 	steps per sec: 6
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308]
Training time: 3632 	steps per sec: 6
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418]
Training time: 3908 	steps per sec: 6
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538]
Training time: 4173 	steps per sec: 5
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672]
Training time: 4402 	steps per sec: 5
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247]
Training time: 4683 	steps per sec: 5
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974]
Training time: 4937 	steps per sec: 5
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301, 0.003700029104948044]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544, 0.020748252049088478]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522]
Training time: 5175 	steps per sec: 5
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301, 0.003700029104948044, 0.0054310392588377]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544, 0.020748252049088478, 0.019957473501563072]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772]
Training time: 5418 	steps per sec: 5
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301, 0.003700029104948044, 0.0054310392588377, 0.0034479349851608276]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544, 0.020748252049088478, 0.019957473501563072, 0.020941024646162987]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814]
Training time: 5650 	steps per sec: 5
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301, 0.003700029104948044, 0.0054310392588377, 0.0034479349851608276, 0.0006966404616832733]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544, 0.020748252049088478, 0.019957473501563072, 0.020941024646162987, 0.020465023815631866]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814, 0.02116166427731514]
Training time: 5885 	steps per sec: 5
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-0.19644564390182495, -0.02782924473285675, -0.03299422562122345, -0.011283300817012787, -0.009438924491405487, -0.014601994305849075, -0.011548694223165512, -0.01262570545077324, -0.010164419189095497, -0.003646375611424446, -0.006063418462872505, -0.0035060178488492966, -0.006683699786663055, 0.010762738063931465, 0.0050402674823999405, 0.010596396401524544, 0.006254957988858223, 0.00965266302227974, 0.007499471306800842, 0.008453251793980598, 0.01074313372373581, 0.011213203892111778, 0.006004109978675842, 0.007604241371154785, 0.009815054014325142, 0.007351510226726532, 0.005153592675924301, 0.003700029104948044, 0.0054310392588377, 0.0034479349851608276, 0.0006966404616832733, 0.0010501109063625336]
ref [0.7802824378013611, 0.2204369455575943, 0.14581353962421417, 0.0919552594423294, 0.06716837733983994, 0.06237562373280525, 0.050773341208696365, 0.0441727340221405, 0.03678792715072632, 0.03329954296350479, 0.032265011221170425, 0.02732081711292267, 0.02776523306965828, 0.02498711831867695, 0.026014575734734535, 0.018774917349219322, 0.024357568472623825, 0.02154400385916233, 0.02304897829890251, 0.022088926285505295, 0.019812075421214104, 0.01883329264819622, 0.023577189072966576, 0.022223571315407753, 0.02102569490671158, 0.017805274575948715, 0.01994689367711544, 0.020748252049088478, 0.019957473501563072, 0.020941024646162987, 0.020465023815631866, 0.020327534526586533]
[0.5838367938995361, 0.19260770082473755, 0.11281931400299072, 0.08067195862531662, 0.05772945284843445, 0.04777362942695618, 0.03922464698553085, 0.031547028571367264, 0.02662350796163082, 0.029653167352080345, 0.02620159275829792, 0.023814799264073372, 0.021081533282995224, 0.035749856382608414, 0.031054843217134476, 0.029371313750743866, 0.030612526461482048, 0.03119666688144207, 0.030548449605703354, 0.030542178079485893, 0.030555209144949913, 0.030046496540308, 0.029581299051642418, 0.029827812686562538, 0.03084074892103672, 0.025156784802675247, 0.02510048635303974, 0.024448281154036522, 0.025388512760400772, 0.024388959631323814, 0.02116166427731514, 0.021377645432949066]
Training time: 6126 	steps per sec: 5
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Ant-v4/
results/Ant-v4/ppo_ros/
results/Ant-v4/ppo_ros/expert/
results/Ant-v4/ppo_ros/expert/b_16/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/config.yml
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/evaluations.npz
results/Ant-v4/ppo_ros/expert/b_16/no_clip/run_0/stats.npz
