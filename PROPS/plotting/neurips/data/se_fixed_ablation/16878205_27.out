ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_23333/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_23333/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_23333/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_23333/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 2
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.4392361640930176]
ref [2.077092409133911]
[2.5163285732269287]
Training time: 32 	steps per sec: 31
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.4392361640930176, 0.059359729290008545]
ref [2.077092409133911, 0.6673339605331421]
[2.5163285732269287, 0.7266936898231506]
Training time: 80 	steps per sec: 25
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079]
Training time: 143 	steps per sec: 21
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987]
Training time: 220 	steps per sec: 18
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517]
Training time: 308 	steps per sec: 16
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686]
Training time: 412 	steps per sec: 14
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572]
Training time: 539 	steps per sec: 13
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432]
Training time: 675 	steps per sec: 12
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894]
Training time: 824 	steps per sec: 11
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303]
Training time: 986 	steps per sec: 10
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775]
Training time: 1177 	steps per sec: 9
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755]
Training time: 1393 	steps per sec: 8
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735]
Training time: 1641 	steps per sec: 8
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965]
Training time: 1926 	steps per sec: 7
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345]
Training time: 2238 	steps per sec: 6
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024]
Training time: 2582 	steps per sec: 6
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614]
Training time: 2907 	steps per sec: 5
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051]
Training time: 3227 	steps per sec: 5
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366]
Training time: 3542 	steps per sec: 5
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984]
Training time: 3861 	steps per sec: 5
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566]
Training time: 4187 	steps per sec: 5
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855]
Training time: 4512 	steps per sec: 4
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866]
Training time: 4841 	steps per sec: 4
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536]
Training time: 5157 	steps per sec: 4
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586]
Training time: 5475 	steps per sec: 4
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131]
Training time: 5800 	steps per sec: 4
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276]
Training time: 6129 	steps per sec: 4
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164, -0.0025052614510059357]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344, 0.04345318302512169]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276, 0.04094792157411575]
Training time: 6454 	steps per sec: 4
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164, -0.0025052614510059357, -0.0029072165489196777]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344, 0.04345318302512169, 0.044076867401599884]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276, 0.04094792157411575, 0.041169650852680206]
Training time: 6779 	steps per sec: 4
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164, -0.0025052614510059357, -0.0029072165489196777, -0.004194770008325577]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344, 0.04345318302512169, 0.044076867401599884, 0.04549647867679596]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276, 0.04094792157411575, 0.041169650852680206, 0.04130170866847038]
Training time: 7109 	steps per sec: 4
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164, -0.0025052614510059357, -0.0029072165489196777, -0.004194770008325577, -0.0036137551069259644]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344, 0.04345318302512169, 0.044076867401599884, 0.04549647867679596, 0.044658113270998]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276, 0.04094792157411575, 0.041169650852680206, 0.04130170866847038, 0.04104435816407204]
Training time: 7413 	steps per sec: 4
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.4392361640930176, 0.059359729290008545, -0.022677898406982422, -0.014141768217086792, -0.01539216935634613, -0.01580396294593811, -0.02343718707561493, -0.022611409425735474, -0.00928238034248352, -0.01588056981563568, -0.014811273664236069, -0.008694212883710861, -0.009836394339799881, -0.008551008999347687, -0.010466154664754868, -0.01041308045387268, -0.012218743562698364, -0.00738685205578804, -0.005230233073234558, -0.002877861261367798, -0.003991581499576569, -0.0018235184252262115, -0.0017442479729652405, -0.0019445084035396576, -0.0031477734446525574, -0.007447689771652222, -0.006297606974840164, -0.0025052614510059357, -0.0029072165489196777, -0.004194770008325577, -0.0036137551069259644, -0.005602505058050156]
ref [2.077092409133911, 0.6673339605331421, 0.3604566752910614, 0.25166475772857666, 0.1865028589963913, 0.15559951961040497, 0.13285744190216064, 0.11053953319787979, 0.08349013328552246, 0.08231968432664871, 0.07546895742416382, 0.06290250271558762, 0.058748479932546616, 0.052843641489744186, 0.05057219788432121, 0.04747827351093292, 0.04791313409805298, 0.04506514593958855, 0.043623123317956924, 0.04111095517873764, 0.04398253560066223, 0.042923055589199066, 0.042709819972515106, 0.042354781180620193, 0.041889943182468414, 0.047989778220653534, 0.04724062979221344, 0.04345318302512169, 0.044076867401599884, 0.04549647867679596, 0.044658113270998, 0.046553947031497955]
[2.5163285732269287, 0.7266936898231506, 0.337778776884079, 0.23752298951148987, 0.17111068964004517, 0.13979555666446686, 0.10942025482654572, 0.08792812377214432, 0.07420775294303894, 0.06643911451101303, 0.06065768375992775, 0.054208289831876755, 0.048912085592746735, 0.0442926324903965, 0.040106043219566345, 0.03706519305706024, 0.035694390535354614, 0.03767829388380051, 0.038392890244722366, 0.03823309391736984, 0.03999095410108566, 0.041099537163972855, 0.040965571999549866, 0.040410272777080536, 0.03874216973781586, 0.04054208844900131, 0.040943022817373276, 0.04094792157411575, 0.041169650852680206, 0.04130170866847038, 0.04104435816407204, 0.0409514419734478]
Training time: 7745 	steps per sec: 4
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_2/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_2/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_2/config.yml
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_2/stats.npz
