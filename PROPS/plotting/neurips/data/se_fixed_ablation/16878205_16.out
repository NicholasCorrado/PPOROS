ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0.3 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_604186/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_604186/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_604186/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_604186/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 1
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.222214937210083]
ref [2.2050228118896484]
[2.4272377490997314]
Training time: 20 	steps per sec: 50
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.222214937210083, -0.11555248498916626]
ref [2.2050228118896484, 0.9355351328849792]
[2.4272377490997314, 0.819982647895813]
Training time: 50 	steps per sec: 40
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326]
Training time: 92 	steps per sec: 33
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679]
Training time: 144 	steps per sec: 28
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046]
Training time: 211 	steps per sec: 24
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808]
Training time: 294 	steps per sec: 20
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817]
Training time: 382 	steps per sec: 18
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006]
Training time: 474 	steps per sec: 17
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824]
Training time: 590 	steps per sec: 15
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627]
Training time: 698 	steps per sec: 14
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766]
Training time: 824 	steps per sec: 13
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121]
Training time: 967 	steps per sec: 12
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996]
Training time: 1105 	steps per sec: 12
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575]
Training time: 1267 	steps per sec: 11
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684]
Training time: 1403 	steps per sec: 10
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606]
Training time: 1595 	steps per sec: 10
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635]
Training time: 1775 	steps per sec: 9
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915]
Training time: 1918 	steps per sec: 9
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005]
Training time: 2061 	steps per sec: 9
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928]
Training time: 2208 	steps per sec: 9
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075]
Training time: 2417 	steps per sec: 8
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691]
Training time: 2592 	steps per sec: 8
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173]
Training time: 2737 	steps per sec: 8
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583]
Training time: 2906 	steps per sec: 8
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291]
Training time: 3051 	steps per sec: 8
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985]
Training time: 3195 	steps per sec: 8
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309]
Training time: 3343 	steps per sec: 8
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532, -0.0072205327451229095]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625, 0.045042984187603]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309, 0.03782245144248009]
Training time: 3476 	steps per sec: 8
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532, -0.0072205327451229095, -0.007492884993553162]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625, 0.045042984187603, 0.045553937554359436]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309, 0.03782245144248009, 0.038061052560806274]
Training time: 3684 	steps per sec: 8
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532, -0.0072205327451229095, -0.007492884993553162, -0.0065228939056396484]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625, 0.045042984187603, 0.045553937554359436, 0.044627949595451355]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309, 0.03782245144248009, 0.038061052560806274, 0.03810505568981171]
Training time: 3860 	steps per sec: 7
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532, -0.0072205327451229095, -0.007492884993553162, -0.0065228939056396484, -0.00848674401640892]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625, 0.045042984187603, 0.045553937554359436, 0.044627949595451355, 0.04608459770679474]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309, 0.03782245144248009, 0.038061052560806274, 0.03810505568981171, 0.03759785369038582]
Training time: 4002 	steps per sec: 7
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.222214937210083, -0.11555248498916626, -0.012215733528137207, -0.04311788082122803, -0.002473771572113037, -0.02664196491241455, -0.010758675634860992, -0.010058186948299408, -0.001328013837337494, -0.011192210018634796, -0.004029653966426849, -0.012265123426914215, -0.009433038532733917, -0.007230482995510101, -0.004468608647584915, -0.0053170472383499146, -0.005799304693937302, -0.004717469215393066, -0.0054316446185112, -0.007327493280172348, -0.0004439800977706909, -0.0006679147481918335, -0.008961483836174011, -0.003282994031906128, -0.002340506762266159, -0.005017075687646866, -0.011046558618545532, -0.0072205327451229095, -0.007492884993553162, -0.0065228939056396484, -0.00848674401640892, -0.00880676880478859]
ref [2.2050228118896484, 0.9355351328849792, 0.3719768226146698, 0.30306583642959595, 0.19557882845401764, 0.16527587175369263, 0.12533724308013916, 0.10876365005970001, 0.08632325381040573, 0.08505718410015106, 0.0677710473537445, 0.06844069808721542, 0.059180185198783875, 0.052939146757125854, 0.0472019761800766, 0.04563123732805252, 0.04666198417544365, 0.04525906592607498, 0.047441743314266205, 0.04780377820134163, 0.040987126529216766, 0.040056146681308746, 0.04881009832024574, 0.044053927063941956, 0.04408247396349907, 0.04533688724040985, 0.048745229840278625, 0.045042984187603, 0.045553937554359436, 0.044627949595451355, 0.04608459770679474, 0.04567476361989975]
[2.4272377490997314, 0.819982647895813, 0.3597610890865326, 0.2599479556083679, 0.1931050568819046, 0.13863390684127808, 0.11457856744527817, 0.0987054631114006, 0.08499523997306824, 0.07386497408151627, 0.06374139338731766, 0.05617557466030121, 0.04974714666604996, 0.04570866376161575, 0.042733367532491684, 0.040314190089702606, 0.04086267948150635, 0.040541596710681915, 0.042010098695755005, 0.04047628492116928, 0.040543146431446075, 0.03938823193311691, 0.03984861448407173, 0.04077093303203583, 0.04174196720123291, 0.040319811552762985, 0.03769867122173309, 0.03782245144248009, 0.038061052560806274, 0.03810505568981171, 0.03759785369038582, 0.03686799481511116]
Training time: 4147 	steps per sec: 7
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_1/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_1/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_1/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip/run_1/config.yml
