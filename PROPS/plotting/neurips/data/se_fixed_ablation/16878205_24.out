ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 0.3 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_2480813/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_2480813/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_2480813/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_2480813/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 4
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [-1.2454822063446045]
ref [3.64723801612854]
[2.4017558097839355]
Training time: 13 	steps per sec: 75
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [-1.2454822063446045, -0.015000224113464355]
ref [3.64723801612854, 0.6728357076644897]
[2.4017558097839355, 0.6578354835510254]
Training time: 30 	steps per sec: 66
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973]
Training time: 55 	steps per sec: 55
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016]
Training time: 86 	steps per sec: 47
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798]
Training time: 124 	steps per sec: 41
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907]
Training time: 169 	steps per sec: 36
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896]
Training time: 221 	steps per sec: 32
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465]
Training time: 282 	steps per sec: 29
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164]
Training time: 350 	steps per sec: 26
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541]
Training time: 425 	steps per sec: 24
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412]
Training time: 510 	steps per sec: 22
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356]
Training time: 606 	steps per sec: 20
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631]
Training time: 718 	steps per sec: 18
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901]
Training time: 864 	steps per sec: 16
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738]
Training time: 1015 	steps per sec: 15
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076]
Training time: 1159 	steps per sec: 14
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207]
Training time: 1293 	steps per sec: 13
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799]
Training time: 1421 	steps per sec: 12
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533]
Training time: 1548 	steps per sec: 12
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804]
Training time: 1675 	steps per sec: 12
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292]
Training time: 1804 	steps per sec: 11
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384]
Training time: 1933 	steps per sec: 11
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006]
Training time: 2061 	steps per sec: 11
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149]
Training time: 2190 	steps per sec: 11
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446]
Training time: 2317 	steps per sec: 11
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095]
Training time: 2446 	steps per sec: 10
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428]
Training time: 2584 	steps per sec: 10
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278, -0.00802299752831459]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556, 0.04478495568037033]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428, 0.03676195815205574]
Training time: 2742 	steps per sec: 10
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278, -0.00802299752831459, -0.006313979625701904]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556, 0.04478495568037033, 0.04394923150539398]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428, 0.03676195815205574, 0.03763525187969208]
Training time: 2887 	steps per sec: 10
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278, -0.00802299752831459, -0.006313979625701904, -0.008921217173337936]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556, 0.04478495568037033, 0.04394923150539398, 0.045819275081157684]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428, 0.03676195815205574, 0.03763525187969208, 0.03689805790781975]
Training time: 3034 	steps per sec: 10
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278, -0.00802299752831459, -0.006313979625701904, -0.008921217173337936, -0.007363807410001755]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556, 0.04478495568037033, 0.04394923150539398, 0.045819275081157684, 0.043017107993364334]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428, 0.03676195815205574, 0.03763525187969208, 0.03689805790781975, 0.03565330058336258]
Training time: 3227 	steps per sec: 9
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [-1.2454822063446045, -0.015000224113464355, -0.07420092821121216, -0.05432778596878052, -0.03352215886116028, -0.021702095866203308, -0.02064366638660431, -0.01586022973060608, -0.0242554172873497, -0.010285351425409317, -0.019568227231502533, -0.012509677559137344, -0.010629020631313324, -0.00876782089471817, -0.008132677525281906, -0.009872499853372574, -0.004107605665922165, -0.009043805301189423, -0.008009891957044601, -0.005991198122501373, -0.00760115310549736, -0.007547974586486816, -0.004606664180755615, -0.011922940611839294, -0.004999089986085892, -0.006894554942846298, -0.006599601358175278, -0.00802299752831459, -0.006313979625701904, -0.008921217173337936, -0.007363807410001755, -0.004830300807952881]
ref [3.64723801612854, 0.6728357076644897, 0.42110225558280945, 0.2934873700141907, 0.21096980571746826, 0.16063295304775238, 0.12359698116779327, 0.10190562903881073, 0.09691186249256134, 0.07247699797153473, 0.07515158504247665, 0.0612109936773777, 0.05575479939579964, 0.05046230927109718, 0.046249911189079285, 0.04427099972963333, 0.03996147960424423, 0.046878837049007416, 0.04706359654664993, 0.04399792477488518, 0.04589968919754028, 0.0459919273853302, 0.042663395404815674, 0.050167787820100784, 0.04283980652689934, 0.044158339500427246, 0.044152501970529556, 0.04478495568037033, 0.04394923150539398, 0.045819275081157684, 0.043017107993364334, 0.04171079397201538]
[2.4017558097839355, 0.6578354835510254, 0.3469013273715973, 0.23915958404541016, 0.17744764685630798, 0.13893085718154907, 0.10295331478118896, 0.08604539930820465, 0.07265644520521164, 0.06219164654612541, 0.05558335781097412, 0.048701316118240356, 0.04512577876448631, 0.04169448837637901, 0.03811723366379738, 0.03439849987626076, 0.03585387393832207, 0.03783503174781799, 0.03905370458960533, 0.038006726652383804, 0.03829853609204292, 0.038443952798843384, 0.03805673122406006, 0.03824484720826149, 0.037840716540813446, 0.03726378455758095, 0.03755290061235428, 0.03676195815205574, 0.03763525187969208, 0.03689805790781975, 0.03565330058336258, 0.0368804931640625]
Training time: 3439 	steps per sec: 9
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_4/
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_4/config.yml
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_4/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_lambda/run_4/stats.npz
