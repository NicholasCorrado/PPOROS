ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_38006/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_38006/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_38006/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_38006/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 3
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [0.08543133735656738]
ref [2.3265485763549805]
[2.411979913711548]
Training time: 55 	steps per sec: 18
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [0.08543133735656738, -0.14705276489257812]
ref [2.3265485763549805, 0.8185145854949951]
[2.411979913711548, 0.671461820602417]
Training time: 126 	steps per sec: 16
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685]
[2.411979913711548, 0.671461820602417, 0.39358222484588623]
Training time: 218 	steps per sec: 14
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789]
Training time: 343 	steps per sec: 11
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602]
Training time: 506 	steps per sec: 10
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282]
Training time: 712 	steps per sec: 8
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435]
Training time: 921 	steps per sec: 7
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168]
Training time: 1152 	steps per sec: 7
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845]
Training time: 1401 	steps per sec: 6
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763]
Training time: 1703 	steps per sec: 6
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335]
Training time: 1993 	steps per sec: 5
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574]
Training time: 2321 	steps per sec: 5
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412]
Training time: 2687 	steps per sec: 4
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586]
Training time: 3073 	steps per sec: 4
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287]
Training time: 3474 	steps per sec: 4
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076]
Training time: 3936 	steps per sec: 4
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935]
Training time: 4392 	steps per sec: 3
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978]
Training time: 4832 	steps per sec: 3
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724]
Training time: 5276 	steps per sec: 3
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882]
Training time: 5725 	steps per sec: 3
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746]
Training time: 6146 	steps per sec: 3
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518]
Training time: 6601 	steps per sec: 3
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669]
Training time: 7080 	steps per sec: 3
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579]
Training time: 7518 	steps per sec: 3
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256]
Training time: 7972 	steps per sec: 3
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297]
Training time: 8430 	steps per sec: 3
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887]
Training time: 8898 	steps per sec: 3
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652, -0.010271824896335602]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354, 0.04906175285577774]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887, 0.03878992795944214]
Training time: 9361 	steps per sec: 3
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652, -0.010271824896335602, -0.007848396897315979]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354, 0.04906175285577774, 0.047556616365909576]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887, 0.03878992795944214, 0.0397082194685936]
Training time: 9821 	steps per sec: 3
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652, -0.010271824896335602, -0.007848396897315979, -0.006006896495819092]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354, 0.04906175285577774, 0.047556616365909576, 0.04529258981347084]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887, 0.03878992795944214, 0.0397082194685936, 0.03928569331765175]
Training time: 10286 	steps per sec: 2
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652, -0.010271824896335602, -0.007848396897315979, -0.006006896495819092, -0.010480064898729324]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354, 0.04906175285577774, 0.047556616365909576, 0.04529258981347084, 0.04740085452795029]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887, 0.03878992795944214, 0.0397082194685936, 0.03928569331765175, 0.03692078962922096]
Training time: 10720 	steps per sec: 2
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [0.08543133735656738, -0.14705276489257812, -0.04783836007118225, -0.019383400678634644, -0.028896018862724304, 0.0050201416015625, 0.00842132419347763, -0.010728694498538971, -0.000662483274936676, -0.003234066069126129, -0.0016226693987846375, -0.0059654489159584045, -0.00833897665143013, -0.0016711913049221039, -0.0008224472403526306, -9.008869528770447e-05, -0.003218434751033783, -0.006558701395988464, -0.007440619170665741, -0.0067121051251888275, -0.007291823625564575, -0.006253324449062347, -0.01072356104850769, -0.005984887480735779, -0.006623543798923492, -0.004812691360712051, -0.008721120655536652, -0.010271824896335602, -0.007848396897315979, -0.006006896495819092, -0.010480064898729324, -0.009044893085956573]
ref [2.3265485763549805, 0.8185145854949951, 0.4414205849170685, 0.27447253465652466, 0.21751494705677032, 0.13891427218914032, 0.11583232879638672, 0.11043282598257065, 0.08683624118566513, 0.08022208511829376, 0.06976902484893799, 0.06677541881799698, 0.06099972501397133, 0.05033295601606369, 0.0446549616754055, 0.039334580302238464, 0.044103868305683136, 0.047653332352638245, 0.047088466584682465, 0.045224275439977646, 0.04602845013141632, 0.04418405517935753, 0.049763552844524384, 0.04533054307103157, 0.04535990208387375, 0.04394986853003502, 0.048341408371925354, 0.04906175285577774, 0.047556616365909576, 0.04529258981347084, 0.04740085452795029, 0.046109639108181]
[2.411979913711548, 0.671461820602417, 0.39358222484588623, 0.25508913397789, 0.18861892819404602, 0.14393441379070282, 0.12425365298986435, 0.09970413148403168, 0.08617375791072845, 0.07698801904916763, 0.06814635545015335, 0.060809969902038574, 0.0526607483625412, 0.048661764711141586, 0.04383251443505287, 0.03924449160695076, 0.04088543355464935, 0.04109463095664978, 0.039647847414016724, 0.03851217031478882, 0.038736626505851746, 0.03793073073029518, 0.03903999179601669, 0.03934565559029579, 0.038736358284950256, 0.03913717716932297, 0.0396202877163887, 0.03878992795944214, 0.0397082194685936, 0.03928569331765175, 0.03692078962922096, 0.037064746022224426]
Training time: 11197 	steps per sec: 2
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_3/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_3/config.yml
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_3/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_3/stats.npz
