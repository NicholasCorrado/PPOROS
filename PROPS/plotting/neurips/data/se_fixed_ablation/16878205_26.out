ppo_ros_continuous.py --env-id Humanoid-v4 -s expert/b_16/no_clip_lambda --total-timesteps 32768 --eval-freq 1 --eval-episodes 0 -b 16 --num-steps 1024 -lr 0 --update-epochs 0 --anneal-lr 0 --ros-num-steps 256 --ros-update-epochs 16 --ros-target-kl 0.05 --ros-clip-coef 999999999 --ros-lambda 0 -ros-lr 0.0001 --ros-anneal-lr 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
Obtaining file:///var/lib/condor/execute/slot1/dir_17792/PPOROS/PPOROS/custom-envs
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: gym in /var/lib/condor/execute/slot1/dir_17792/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from custom-envs==0.0.1) (0.21.0)
Requirement already satisfied: numpy>=1.18.0 in /var/lib/condor/execute/slot1/dir_17792/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (1.24.2)
Requirement already satisfied: cloudpickle>=1.2.0 in /var/lib/condor/execute/slot1/dir_17792/PPOROS/ppo-ros_env/lib/python3.9/site-packages (from gym->custom-envs==0.0.1) (2.2.1)
Installing collected packages: custom-envs
  Running setup.py develop for custom-envs
Successfully installed custom-envs-0.0.1
seed: 1
Eval num_timesteps=0, episode_reward=nan +/- nan
Eval num_timesteps=0, episode_success=nan +/- nan
se
1 1024 1024
diff [2.048699736595154]
ref [1.9824382066726685]
[4.031137943267822]
Training time: 41 	steps per sec: 24
Eval num_timesteps=1024, episode_reward=nan +/- nan
Eval num_timesteps=1024, episode_success=nan +/- nan
se
2 2048 1024
diff [2.048699736595154, 0.6167809963226318]
ref [1.9824382066726685, 0.8007084131240845]
[4.031137943267822, 1.4174894094467163]
Training time: 103 	steps per sec: 19
Eval num_timesteps=2048, episode_reward=nan +/- nan
Eval num_timesteps=2048, episode_success=nan +/- nan
se
3 3072 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914]
Training time: 184 	steps per sec: 16
Eval num_timesteps=3072, episode_reward=nan +/- nan
Eval num_timesteps=3072, episode_success=nan +/- nan
se
4 4096 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483]
Training time: 281 	steps per sec: 14
Eval num_timesteps=4096, episode_reward=nan +/- nan
Eval num_timesteps=4096, episode_success=nan +/- nan
se
5 5120 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012]
Training time: 398 	steps per sec: 12
Eval num_timesteps=5120, episode_reward=nan +/- nan
Eval num_timesteps=5120, episode_success=nan +/- nan
se
6 6144 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027]
Training time: 539 	steps per sec: 11
Eval num_timesteps=6144, episode_reward=nan +/- nan
Eval num_timesteps=6144, episode_success=nan +/- nan
se
7 7168 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373]
Training time: 699 	steps per sec: 10
Eval num_timesteps=7168, episode_reward=nan +/- nan
Eval num_timesteps=7168, episode_success=nan +/- nan
se
8 8192 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889]
Training time: 877 	steps per sec: 9
Eval num_timesteps=8192, episode_reward=nan +/- nan
Eval num_timesteps=8192, episode_success=nan +/- nan
se
9 9216 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578]
Training time: 1077 	steps per sec: 8
Eval num_timesteps=9216, episode_reward=nan +/- nan
Eval num_timesteps=9216, episode_success=nan +/- nan
se
10 10240 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346]
Training time: 1293 	steps per sec: 7
Eval num_timesteps=10240, episode_reward=nan +/- nan
Eval num_timesteps=10240, episode_success=nan +/- nan
se
11 11264 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856]
Training time: 1552 	steps per sec: 7
Eval num_timesteps=11264, episode_reward=nan +/- nan
Eval num_timesteps=11264, episode_success=nan +/- nan
se
12 12288 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303]
Training time: 1839 	steps per sec: 6
Eval num_timesteps=12288, episode_reward=nan +/- nan
Eval num_timesteps=12288, episode_success=nan +/- nan
se
13 13312 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316]
Training time: 2145 	steps per sec: 6
Eval num_timesteps=13312, episode_reward=nan +/- nan
Eval num_timesteps=13312, episode_success=nan +/- nan
se
14 14336 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694]
Training time: 2473 	steps per sec: 5
Eval num_timesteps=14336, episode_reward=nan +/- nan
Eval num_timesteps=14336, episode_success=nan +/- nan
se
15 15360 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856]
Training time: 2820 	steps per sec: 5
Eval num_timesteps=15360, episode_reward=nan +/- nan
Eval num_timesteps=15360, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826]
Training time: 3179 	steps per sec: 5
Eval num_timesteps=16384, episode_reward=nan +/- nan
Eval num_timesteps=16384, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559]
Training time: 3536 	steps per sec: 4
Eval num_timesteps=17408, episode_reward=nan +/- nan
Eval num_timesteps=17408, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489]
Training time: 3905 	steps per sec: 4
Eval num_timesteps=18432, episode_reward=nan +/- nan
Eval num_timesteps=18432, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843]
Training time: 4273 	steps per sec: 4
Eval num_timesteps=19456, episode_reward=nan +/- nan
Eval num_timesteps=19456, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836]
Training time: 4648 	steps per sec: 4
Eval num_timesteps=20480, episode_reward=nan +/- nan
Eval num_timesteps=20480, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991]
Training time: 5034 	steps per sec: 4
Eval num_timesteps=21504, episode_reward=nan +/- nan
Eval num_timesteps=21504, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675]
Training time: 5409 	steps per sec: 4
Eval num_timesteps=22528, episode_reward=nan +/- nan
Eval num_timesteps=22528, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336]
Training time: 5782 	steps per sec: 4
Eval num_timesteps=23552, episode_reward=nan +/- nan
Eval num_timesteps=23552, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605]
Training time: 6157 	steps per sec: 3
Eval num_timesteps=24576, episode_reward=nan +/- nan
Eval num_timesteps=24576, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276]
Training time: 6532 	steps per sec: 3
Eval num_timesteps=25600, episode_reward=nan +/- nan
Eval num_timesteps=25600, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735]
Training time: 6918 	steps per sec: 3
Eval num_timesteps=26624, episode_reward=nan +/- nan
Eval num_timesteps=26624, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236]
Training time: 7295 	steps per sec: 3
Eval num_timesteps=27648, episode_reward=nan +/- nan
Eval num_timesteps=27648, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591, -0.004733186215162277]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954, 0.042348917573690414]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236, 0.03761573135852814]
Training time: 7678 	steps per sec: 3
Eval num_timesteps=28672, episode_reward=nan +/- nan
Eval num_timesteps=28672, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591, -0.004733186215162277, -0.004569772630929947]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954, 0.042348917573690414, 0.04257247596979141]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236, 0.03761573135852814, 0.038002703338861465]
Training time: 8062 	steps per sec: 3
Eval num_timesteps=29696, episode_reward=nan +/- nan
Eval num_timesteps=29696, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591, -0.004733186215162277, -0.004569772630929947, -0.007260724902153015]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954, 0.042348917573690414, 0.04257247596979141, 0.04568567872047424]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236, 0.03761573135852814, 0.038002703338861465, 0.03842495381832123]
Training time: 8432 	steps per sec: 3
Eval num_timesteps=30720, episode_reward=nan +/- nan
Eval num_timesteps=30720, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591, -0.004733186215162277, -0.004569772630929947, -0.007260724902153015, -0.005989108234643936]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954, 0.042348917573690414, 0.04257247596979141, 0.04568567872047424, 0.04381104186177254]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236, 0.03761573135852814, 0.038002703338861465, 0.03842495381832123, 0.0378219336271286]
Training time: 8801 	steps per sec: 3
Eval num_timesteps=31744, episode_reward=nan +/- nan
Eval num_timesteps=31744, episode_success=nan +/- nan
se
16 16384 1024
diff [2.048699736595154, 0.6167809963226318, -0.0021875202655792236, 0.0359748899936676, 0.023575007915496826, -0.00609666109085083, -0.016751430928707123, -0.011145517230033875, -0.012618102133274078, -0.005367092788219452, -0.008391879498958588, -0.008873086422681808, -0.0068879276514053345, -0.006709691137075424, -0.0033422596752643585, -0.005537204444408417, -0.0033986568450927734, -0.010065458714962006, -0.008851341903209686, -0.007080018520355225, -0.008042816072702408, -0.0037708207964897156, -0.008110713213682175, -0.007389005273580551, -0.009732760488986969, -0.01063656434416771, -0.004307117313146591, -0.004733186215162277, -0.004569772630929947, -0.007260724902153015, -0.005989108234643936, -0.01223694533109665]
ref [1.9824382066726685, 0.8007084131240845, 0.43251943588256836, 0.27527526021003723, 0.1807607114315033, 0.1527789980173111, 0.13374339044094086, 0.10840433835983276, 0.09617867320775986, 0.07640943676233292, 0.07362209260463715, 0.06580307334661484, 0.05748094618320465, 0.05335910990834236, 0.04658721014857292, 0.04562464356422424, 0.040905267000198364, 0.046518485993146896, 0.04530765861272812, 0.044421032071113586, 0.04556221142411232, 0.04180523008108139, 0.04483368620276451, 0.043845873326063156, 0.046919699758291245, 0.04842640459537506, 0.042639221996068954, 0.042348917573690414, 0.04257247596979141, 0.04568567872047424, 0.04381104186177254, 0.04803377017378807]
[4.031137943267822, 1.4174894094467163, 0.43033191561698914, 0.31125015020370483, 0.20433571934700012, 0.14668233692646027, 0.11699195951223373, 0.09725882112979889, 0.08356057107448578, 0.07104234397411346, 0.06523021310567856, 0.05692998692393303, 0.050593018531799316, 0.04664941877126694, 0.04324495047330856, 0.040087439119815826, 0.03750661015510559, 0.03645302727818489, 0.03645631670951843, 0.03734101355075836, 0.03751939535140991, 0.038034409284591675, 0.036722972989082336, 0.036456868052482605, 0.037186939269304276, 0.03778984025120735, 0.03833210468292236, 0.03761573135852814, 0.038002703338861465, 0.03842495381832123, 0.0378219336271286, 0.03579682484269142]
Training time: 9165 	steps per sec: 3
Eval num_timesteps=32768, episode_reward=nan +/- nan
Eval num_timesteps=32768, episode_success=nan +/- nan
results/Humanoid-v4/
results/Humanoid-v4/ppo_ros/
results/Humanoid-v4/ppo_ros/expert/
results/Humanoid-v4/ppo_ros/expert/b_16/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_1/
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_1/evaluations.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_1/stats.npz
results/Humanoid-v4/ppo_ros/expert/b_16/no_clip_lambda/run_1/config.yml
