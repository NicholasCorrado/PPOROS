python ppo_props_continuous.py --env-id Ant-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id Humanoid-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id Walker2d-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id Hopper-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id HalfCheetah-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id Swimmer-v4 -s random --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000
python ppo_props_continuous.py --env-id Ant-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Ant-v4/best_model.zip --normalization-dir policies/Ant-v4
python ppo_props_continuous.py --env-id Humanoid-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Humanoid-v4/best_model.zip --normalization-dir policies/Humanoid-v4
python ppo_props_continuous.py --env-id Walker2d-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Walker2d-v4/best_model.zip --normalization-dir policies/Walker2d-v4
python ppo_props_continuous.py --env-id Hopper-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Hopper-v4/best_model.zip --normalization-dir policies/Hopper-v4
python ppo_props_continuous.py --env-id HalfCheetah-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/HalfCheetah-v4/best_model.zip --normalization-dir policies/HalfCheetah-v4
python ppo_props_continuous.py --env-id Swimmer-v4 -s expert --total-timesteps 65536 --eval-episodes 0 --props 0 -b 32 --num-steps 1024 --se 1 --eval-freq 1 --update-epochs 0 --se 1 --se-freq 1 --se-lr 1e-3 --se-epochs 1000 --policy-path policies/Swimmer-v4/best_model.zip --normalization-dir policies/Swimmer-v4
